{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19b6a230",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6749a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4613cb05",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# NMA Provided Codes\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "The HCP dataset comprises task-based fMRI from a large sample of human subjects. The NMA-curated dataset includes time series data that has been preprocessed and spatially-downsampled by aggregating within 360 regions of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a28f4377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data shared for NMA projects is a subset of the full HCP dataset\n",
    "N_SUBJECTS = 100\n",
    "\n",
    "# The data have already been aggregated into ROIs from the Glasser parcellation\n",
    "N_PARCELS = 360\n",
    "\n",
    "# The acquisition parameters for all tasks were identical\n",
    "TR = 0.72  # Time resolution, in seconds\n",
    "\n",
    "# The parcels are matched across hemispheres with the same order\n",
    "HEMIS = [\"Right\", \"Left\"]\n",
    "\n",
    "# Each experiment was repeated twice in each subject\n",
    "RUNS   = ['LR','RL']\n",
    "N_RUNS = 2\n",
    "\n",
    "# There are 7 tasks. Each has a number of 'conditions'\n",
    "# TIP: look inside the data folders for more fine-graned conditions\n",
    "\n",
    "EXPERIMENTS = {\n",
    "    'MOTOR'      : {'cond':['lf','rf','lh','rh','t','cue']},\n",
    "    'WM'         : {'cond':['0bk_body','0bk_faces','0bk_places','0bk_tools','2bk_body','2bk_faces','2bk_places','2bk_tools']},\n",
    "    'EMOTION'    : {'cond':['fear','neut']},\n",
    "    'GAMBLING'   : {'cond':['loss','win']},\n",
    "    'LANGUAGE'   : {'cond':['math','story']},\n",
    "    'RELATIONAL' : {'cond':['match','relation']},\n",
    "    'SOCIAL'     : {'cond':['ment','rnd']}\n",
    "}\n",
    "\n",
    "subjects = np.loadtxt('subjects_list.txt', dtype='str')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f736e0a",
   "metadata": {},
   "source": [
    "## Understanding the folder organisation\n",
    "\n",
    "The data folder has the following organisation:\n",
    "\n",
    "- hcp\n",
    "  - regions.npy (information on the brain parcellation)\n",
    "  - subjects_list.txt (list of subject IDs)\n",
    "  - subjects (main data folder)\n",
    "    - [subjectID] (subject-specific subfolder)\n",
    "      - EXPERIMENT (one folder per experiment)\n",
    "        - RUN (one folder per run)\n",
    "          - data.npy (the parcellated time series data)\n",
    "          - EVs (EVs folder)\n",
    "            - [ev1.txt] (one file per condition)\n",
    "            - [ev2.txt]\n",
    "            - Stats.txt (behavioural data [where available] - averaged per run)\n",
    "            - Sync.txt (ignore this file)\n",
    "\n",
    "## Region information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1327f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = np.load(f\"regions.npy\").T\n",
    "region_info = dict(\n",
    "    name=regions[0].tolist(),\n",
    "    network=regions[1],\n",
    "    hemi=['Right']*int(N_PARCELS/2) + ['Left']*int(N_PARCELS/2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a90f4",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab3d8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_timeseries(subject, experiment, run, remove_mean=True):\n",
    "  \"\"\"Load timeseries data for a single subject and single run.\n",
    "\n",
    "  Args:\n",
    "    subject (str):      subject ID to load\n",
    "    experiment (str):   Name of experiment\n",
    "    run (int):          (0 or 1)\n",
    "    remove_mean (bool): If True, subtract the parcel-wise mean (typically the mean BOLD signal is not of interest)\n",
    "\n",
    "  Returns\n",
    "    ts (n_parcel x n_timepoint array): Array of BOLD data values\n",
    "\n",
    "  \"\"\"\n",
    "  bold_run  = RUNS[run]\n",
    "  bold_path = f\"subjects/{subject}/{experiment}/tfMRI_{experiment}_{bold_run}\"\n",
    "  bold_file = \"data.npy\"\n",
    "  ts = np.load(f\"{bold_path}/{bold_file}\")\n",
    "  if remove_mean:\n",
    "    ts -= ts.mean(axis=1, keepdims=True)\n",
    "  return ts\n",
    "\n",
    "\n",
    "def load_evs(subject, experiment, run):\n",
    "  \"\"\"Load EVs (explanatory variables) data for one task experiment.\n",
    "\n",
    "  Args:\n",
    "    subject (str): subject ID to load\n",
    "    experiment (str) : Name of experiment\n",
    "    run (int): 0 or 1\n",
    "\n",
    "  Returns\n",
    "    evs (list of lists): A list of frames associated with each condition\n",
    "\n",
    "  \"\"\"\n",
    "  frames_list = []\n",
    "  task_key = f'tfMRI_{experiment}_{RUNS[run]}'\n",
    "  for cond in EXPERIMENTS[experiment]['cond']:\n",
    "    ev_file  = f\"subjects/{subject}/{experiment}/{task_key}/EVs/{cond}.txt\"\n",
    "    ev_array = np.loadtxt(ev_file, ndmin=2, unpack=True)\n",
    "    ev       = dict(zip([\"onset\", \"duration\", \"amplitude\"], ev_array))\n",
    "    # Determine when trial starts, rounded down\n",
    "    start = np.floor(ev[\"onset\"] / TR).astype(int)\n",
    "    # Use trial duration to determine how many frames to include for trial\n",
    "    duration = np.ceil(ev[\"duration\"] / TR).astype(int)\n",
    "    # Take the range of frames that correspond to this specific trial\n",
    "    frames = [s + np.arange(0, d) for s, d in zip(start, duration)]\n",
    "    frames_list.append(frames)\n",
    "\n",
    "  return frames_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6010ee1b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Analysis\n",
    "\n",
    "## Define Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c28540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note that these regions are present in the separately for right and left\n",
    "So use R_ or L_ before these to get the necessary data\n",
    "Define labels for areas\n",
    "\"\"\"\n",
    "DLPFC_LABELS = [\"8C\", \"8Av\", \"i6-8\", \"s6-8\", \"SFL\", \"8BL\", \"9p\", \"9a\", \"8Ad\", \"p9-46v\", \"a9-46v\", \"46\", \"9-46d\"]\n",
    "PFC_LABELS = ['R_'+i for i in DLPFC_LABELS]\n",
    "PFC_LABELS += ['L_'+i for i in DLPFC_LABELS]\n",
    "FFC_LABELS = ['R_FFC', 'L_FFC']\n",
    "BODY_LABELS = ['R_VVC', 'L_VVC']\n",
    "PARA_LABELS = [\"PHA3\", \"STSda\", \"V4t\"]\n",
    "PPA_LABELS = ['R_'+i for i in PARA_LABELS]\n",
    "PPA_LABELS += ['L_'+i for i in PARA_LABELS]\n",
    "LOC_LABELS = ['R_VMV2', 'L_VMV2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ddbc7d",
   "metadata": {},
   "source": [
    "## Some more helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5175b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_area_data(data, area):\n",
    "    \"\"\"Returns the data for a given area label\"\"\"\n",
    "    area_idx = np.where(regions[0] == area)[0] # Get area indices\n",
    "    return data[area_idx, :] # Get that area from the data and return\n",
    "\n",
    "def get_area_mean(data, areas):\n",
    "    mean = []\n",
    "    for area in areas:\n",
    "        mean.append(get_area_data(data, area))\n",
    "    return np.array(mean).mean(axis=0)\n",
    "\n",
    "def get_ev_indices(exp, cond):\n",
    "    \"\"\"Returns the condition (time) indices relating to fMRI data\"\"\"\n",
    "    return EXPERIMENTS[exp]['cond'].index(cond)\n",
    "\n",
    "def get_cond_related_signal(data, evs, idx):\n",
    "    return data[:, evs[idx]]\n",
    "\n",
    "def get_all_subject_data(exp, area_labels, cond, remove_first_n=0, take_mean=False):\n",
    "    \"\"\"\n",
    "    If take_mean, mean is taken across all subjects, so a single timeseries is returned.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    for s in subjects: # For all subjects\n",
    "        for r in [0, 1]: # For all runs\n",
    "            # Get data and event indices\n",
    "            data = load_single_timeseries(subject=s, experiment=exp,\n",
    "                                          run=r, remove_mean=True)\n",
    "            evs = load_evs(subject=s, experiment=exp,run=r)\n",
    "            \n",
    "            idx = get_ev_indices(exp, cond)\n",
    "            \n",
    "            area_data = get_area_mean(data, area_labels)\n",
    "            cond_data = get_cond_related_signal(area_data, evs, idx)[0][0][remove_first_n:]\n",
    "            all_data.append(cond_data)\n",
    "    \n",
    "    all_data = np.array(all_data)\n",
    "    if take_mean:\n",
    "        return all_data.mean(axis=0)\n",
    "    else:\n",
    "        return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1773a8df",
   "metadata": {},
   "source": [
    "For example to get FFC region for 2 back faces task in working memory experiment while also removing the first 4 TRs (for instruction phase reasons), we can use the method below. From the length, we can see we got 200; 100 subjects with 2 runs each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e9a220f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 35)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_subject_data('WM', FFC_LABELS, '2bk_faces', remove_first_n=4).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb55201",
   "metadata": {},
   "source": [
    "We could use take_mean=True to get the mean signal across subjects. This should give length of 35 since there are 39 TRs but we are removing the first 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acac272b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_subject_data('WM', FFC_LABELS, '2bk_faces', remove_first_n=4, take_mean=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f0c730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
